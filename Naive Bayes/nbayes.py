from collections import defaultdict
from math import log


def build_test_data(label_file, image_file):
    flabel = open(label_file, 'r')
    fimage = open(image_file, 'r')

    training_data_count = 0
    training_dict = defaultdict(list)
    image_digit = []
    for digit_line in flabel:
        digit = int(digit_line)
        training_data_count += 1
        for i in range(28):
            image_digit_line = list(fimage.readline().rstrip('\n'))
            image_digit.append(image_digit_line)
        training_dict[digit].append(image_digit)
        image_digit = []

    training_probability = defaultdict(lambda: defaultdict(list))
    probability_digit = defaultdict(list)
    for digit in range(10):
        probability_white = [[0 for x in range(28)] for x in range(28)]
        # probability_grey = [[0 for x in range(28)] for x in range(28)]
        # probability_black = [[0 for x in range(28)] for x in range(28)]
        probability_dark = [[0 for x in range(28)] for x in range(28)]
        digit_images = training_dict[digit]
        image_count = len(digit_images)
        probability_digit[digit].append(image_count / (training_data_count * 1.0))
        for image in digit_images:
            for i in range(28):
                for j in range(28):
                    # if image[i][j] == '#':
                    #     probability_black[i][j] += 1
                    # elif image[i][j] == '+':
                    #     probability_grey[i][j] += 1
                    # else:
                    #     probability_white[i][j] += 1
                    if image[i][j] == '#' or image[i][j] == '+':
                        probability_dark[i][j] += 1
                    else:
                        probability_white[i][j] += 1
        for i in range(28):
            for j in range(28):
                probability_white[i][j] /= (image_count * 1.0)
                # probability_grey[i][j] /= (image_count * 1.0)
                # probability_black[i][j] /= (image_count * 1.0)
                probability_dark[i][j] /= (image_count * 1.0)
        # probability[' '].append(probability_white)
        # probability['+'].append(probability_grey)
        # probability['#'].append(probability_black)
        training_probability[digit]['w'].append(probability_white)
        # training_probability[digit]['+'].append(probability_grey)
        # training_probability[digit]['#'].append(probability_black)
        training_probability[digit]['d'].append(probability_dark)

    # print training_probability.items()
    # print probability_digit.items()
    # print probability_digit[5][0]
    fimage.close()
    flabel.close()
    tlabel = open('testlabels.txt', 'r')
    timage = open('testimages.txt', 'r')
    predict_label = open("output", 'w')

    smoothing_value = 1
    test_data_count = 0
    log_probability = 0
    max_so_far = -1
    test_image_digit = []
    digit_predicted = -1
    # test_dict = defaultdict(list)
    for test_digit_line in tlabel:
        test_data_count += 1
        for i in range(28):
            test_image_digit_line = list(timage.readline().rstrip('\n'))
            test_image_digit.append(test_image_digit_line)
        # print test_image_digit
        for num in range(10):
            for i in range(28):
                for j in range(28):
                    if test_image_digit[i][j] == ' ':
                        log_probability += log(training_probability[num]['w'][0][i][j] + smoothing_value)
                    elif test_image_digit[i][j] == '+' or test_image_digit[i][j] == '#':
                        log_probability += log(training_probability[num]['d'][0][i][j] + smoothing_value)
                    if j + 1 < 28:
                        if test_image_digit[i][j] == ' ' and test_image_digit[i][j + 1] == '#':
                            log_probability += log(training_probability[num]['d'][0][i][j] + smoothing_value)
                    elif j - 1 >= 0:
                        if test_image_digit[i][j] == ' ' and test_image_digit[i][j - 1] == '#':
                            log_probability += log(training_probability[num]['d'][0][i][j] + smoothing_value)
                    if j + 1 < 28:
                        if test_image_digit[i][j] == ' ' and test_image_digit[i][j + 1] == '+':
                            log_probability += log(training_probability[num]['d'][0][i][j] + smoothing_value)
                    elif j - 1 >= 0:
                        if test_image_digit[i][j] == ' ' and test_image_digit[i][j - 1] == '+':
                            log_probability += log(training_probability[num]['d'][0][i][j] + smoothing_value)
                            # elif test_image_digit[i][j] == '#':
                            #     log_probability += log(training_probability[num]['#'][0][i][j] + smoothing_value)
            log_probability += probability_digit[num][0]
            # print log_probability
            if max_so_far < log_probability:
                digit_predicted = num
                max_so_far = log_probability
                # print digit_predicted
            log_probability = 0
        predict_label.write("%d\n" % digit_predicted)
        max_so_far = -1
        test_image_digit = []
    timage.close()
    tlabel.close()
    predict_label.close()

    test_label = open('testlabels.txt', 'r')
    predict_label = open("output", 'r')
    correct = 0
    for test_digit_line in test_label:
        actual_digit = int(test_digit_line)
        predicted_digit = int(predict_label.readline().rstrip('\n'))
        if actual_digit == predicted_digit:
            correct += 1
    print correct



    # for digit_line in tlabel:
    #     fout.write("%d" %int(digit_line))
    #     max_so_far = -1
    #     digit = int(digit_line)
    #
    #     # for num in range(10):
    #     log_probability = 0
    #     print int(digit_line)
    # for i in range(28):
    #     print i
    #     image_digit_line = list(timage.readline().rstrip(('\n')))
    #     print image_digit_line
    #     if image_digit_line[i] == ' ':
    #         log_probability += log(training_probability[num][' '][0][i][j] + smoothing_value)
    # elif image_digit_line[j] == '+':
    #     log_probability += log(training_probability[num]['+'][0][i][j] + smoothing_value)
    # elif image_digit_line[j] == '#':
    #     log_probability += log(training_probability[num]['#'][0][i][j] + smoothing_value)

    # image_digit_line = timage.readline().rstrip(('\n'))
    # print image_digit_line
    # for j in range(1):
    #     fout.write(image_digit_line)
    # print len(image_digit_line)
    # print image_digit_line[0]
    # if (len(image_digit_line) < 28):
    #     print len(image_digit_line)
    #     print "len oops"
    #     print i
    #     print j
    # if(i>27 or j> 27):
    #     print "oops"
    # if image_digit_line[j] == ' ':
    #     log_probability += log(training_probability[num][' '][0][i][j] + smoothing_value)
    # elif image_digit_line[j] == '+':
    #     log_probability += log(training_probability[num]['+'][0][i][j] + smoothing_value)
    # elif image_digit_line[j] == '#':
    #     log_probability += log(training_probability[num]['#'][0][i][j] + smoothing_value)
    #         # print log_probability
    # if max_so_far < log_probability:
    #     digit_predicted = num
    #     max_so_far = log_probability
    #     print digit_predicted

    timage.close()
    tlabel.close()


if __name__ == '__main__':
    build_test_data('traininglabels.txt', 'trainingimages.txt')


    # [[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.008350730688935281, 0.010438413361169102, 0.010438413361169102, 0.020876826722338204, 0.018789144050104383, 0.016701461377870562, 0.020876826722338204, 0.018789144050104383, 0.0041753653444676405, 0.0041753653444676405, 0.0020876826722338203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.008350730688935281, 0.020876826722338204, 0.04175365344467641, 0.09394572025052192, 0.1419624217118998, 0.17118997912317327, 0.21294363256784968, 0.24425887265135698, 0.22129436325678498, 0.22964509394572025, 0.20668058455114824, 0.162839248434238, 0.0918580375782881, 0.07306889352818371, 0.05010438413361169, 0.020876826722338204, 0.0020876826722338203, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.0041753653444676405, 0.022964509394572025, 0.06680584551148225, 0.1315240083507307, 0.13987473903966596, 0.20250521920668058, 0.24425887265135698, 0.2567849686847599, 0.27139874739039666, 0.2567849686847599, 0.2567849686847599, 0.20876826722338204, 0.21920668058455114, 0.1732776617954071, 0.1440501043841336, 0.0709812108559499, 0.037578288100208766, 0.0041753653444676405, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0041753653444676405, 0.0041753653444676405, 0.0041753653444676405, 0.018789144050104383, 0.05010438413361169, 0.11482254697286012, 0.14822546972860126, 0.15866388308977036, 0.19832985386221294, 0.2254697286012526, 0.20250521920668058, 0.19832985386221294, 0.17536534446764093, 0.18789144050104384, 0.21294363256784968, 0.20668058455114824, 0.23173277661795408, 0.18162839248434237, 0.12943632567849686, 0.0709812108559499, 0.012526096033402923, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.0020876826722338203, 0.010438413361169102, 0.04175365344467641, 0.11691022964509394, 0.15031315240083507, 0.1649269311064718, 0.2359081419624217, 0.26931106471816285, 0.2546972860125261, 0.18162839248434237, 0.1544885177453027, 0.1544885177453027, 0.18997912317327767, 0.20668058455114824, 0.24217118997912318, 0.267223382045929, 0.24008350730688935, 0.1544885177453027, 0.0918580375782881, 0.025052192066805846, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.006263048016701462, 0.033402922755741124, 0.07515657620041753, 0.1336116910229645, 0.1524008350730689, 0.24217118997912318, 0.21711899791231734, 0.22755741127348644, 0.19624217118997914, 0.1732776617954071, 0.20668058455114824, 0.21920668058455114, 0.25052192066805845, 0.21085594989561587, 0.27139874739039666, 0.2150313152400835, 0.2588726513569937, 0.22129436325678498, 0.10855949895615867, 0.04384133611691023, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.016701461377870562, 0.06471816283924843, 0.1315240083507307, 0.14822546972860126, 0.22129436325678498, 0.2359081419624217, 0.21920668058455114, 0.1941544885177453, 0.16075156576200417, 0.17954070981210857, 0.21711899791231734, 0.24008350730688935, 0.23173277661795408, 0.24425887265135698, 0.2609603340292276, 0.2150313152400835, 0.21294363256784968, 0.22755741127348644, 0.18789144050104384, 0.05219206680584551, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.04801670146137787, 0.09603340292275574, 0.15866388308977036, 0.20041753653444677, 0.24217118997912318, 0.24217118997912318, 0.22964509394572025, 0.18580375782881003, 0.20041753653444677, 0.20041753653444677, 0.18789144050104384, 0.16701461377870563, 0.21294363256784968, 0.22755741127348644, 0.21920668058455114, 0.23799582463465555, 0.2150313152400835, 0.25052192066805845, 0.23173277661795408, 0.07306889352818371, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.008350730688935281, 0.07515657620041753, 0.13987473903966596, 0.17954070981210857, 0.23799582463465555, 0.24425887265135698, 0.22338204592901878, 0.18789144050104384, 0.22129436325678498, 0.18162839248434237, 0.2045929018789144, 0.13778705636743216, 0.11691022964509394, 0.14613778705636743, 0.22129436325678498, 0.21920668058455114, 0.24843423799582465, 0.24008350730688935, 0.24634655532359082, 0.20250521920668058, 0.11064718162839249, 0.0041753653444676405, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.012526096033402923, 0.13778705636743216, 0.17745302713987474, 0.2045929018789144, 0.25052192066805845, 0.23799582463465555, 0.18997912317327767, 0.19832985386221294, 0.18997912317327767, 0.1732776617954071, 0.081419624217119, 0.04592901878914405, 0.05010438413361169, 0.10855949895615867, 0.15866388308977036, 0.24425887265135698, 0.2651356993736952, 0.22338204592901878, 0.23799582463465555, 0.2045929018789144, 0.12108559498956159, 0.006263048016701462, 0.0020876826722338203, 0.0],
    #  [0.0, 0.0, 0.0020876826722338203, 0.0, 0.033402922755741124, 0.15031315240083507, 0.18789144050104384, 0.21711899791231734, 0.25052192066805845, 0.22129436325678498, 0.18789144050104384, 0.21711899791231734, 0.14613778705636743, 0.1022964509394572, 0.05010438413361169, 0.033402922755741124, 0.031315240083507306, 0.08350730688935282, 0.1440501043841336, 0.1941544885177453, 0.2630480167014614, 0.23173277661795408, 0.22964509394572025, 0.20041753653444677, 0.12317327766179541, 0.0041753653444676405, 0.0020876826722338203, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.04384133611691023, 0.17536534446764093, 0.21920668058455114, 0.24008350730688935, 0.21085594989561587, 0.20876826722338204, 0.1941544885177453, 0.17954070981210857, 0.1127348643006263, 0.04592901878914405, 0.022964509394572025, 0.014613778705636743, 0.031315240083507306, 0.09603340292275574, 0.1336116910229645, 0.21920668058455114, 0.24843423799582465, 0.23799582463465555, 0.23799582463465555, 0.1837160751565762, 0.12108559498956159, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0020876826722338203, 0.05845511482254697, 0.19206680584551147, 0.20250521920668058, 0.21920668058455114, 0.20876826722338204, 0.24843423799582465, 0.21711899791231734, 0.1524008350730689, 0.05219206680584551, 0.027139874739039668, 0.0041753653444676405, 0.010438413361169102, 0.04175365344467641, 0.1127348643006263, 0.17118997912317327, 0.20041753653444677, 0.24634655532359082, 0.2546972860125261, 0.2359081419624217, 0.17536534446764093, 0.11482254697286012, 0.0020876826722338203, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0020876826722338203, 0.08350730688935282, 0.18997912317327767, 0.20668058455114824, 0.2150313152400835, 0.2254697286012526, 0.24217118997912318, 0.20041753653444677, 0.07724425887265135, 0.05219206680584551, 0.012526096033402923, 0.010438413361169102, 0.04384133611691023, 0.08559498956158663, 0.1419624217118998, 0.18789144050104384, 0.1941544885177453, 0.24008350730688935, 0.24843423799582465, 0.22964509394572025, 0.15657620041753653, 0.08768267223382047, 0.0020876826722338203, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.11482254697286012, 0.18997912317327767, 0.2045929018789144, 0.20668058455114824, 0.24008350730688935, 0.24425887265135698, 0.2045929018789144, 0.07724425887265135, 0.05010438413361169, 0.029227557411273485, 0.04592901878914405, 0.07515657620041753, 0.1419624217118998, 0.22338204592901878, 0.18789144050104384, 0.2150313152400835, 0.27139874739039666, 0.2609603340292276, 0.17536534446764093, 0.1440501043841336, 0.06263048016701461, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0020876826722338203, 0.11482254697286012, 0.1941544885177453, 0.19624217118997914, 0.2045929018789144, 0.2630480167014614, 0.2254697286012526, 0.1837160751565762, 0.11691022964509394, 0.10855949895615867, 0.0918580375782881, 0.10855949895615867, 0.15866388308977036, 0.23799582463465555, 0.21085594989561587, 0.18162839248434237, 0.24634655532359082, 0.23173277661795408, 0.20876826722338204, 0.18162839248434237, 0.10020876826722339, 0.060542797494780795, 0.0020876826722338203, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0041753653444676405, 0.1022964509394572, 0.19624217118997914, 0.22129436325678498, 0.2150313152400835, 0.18789144050104384, 0.24634655532359082, 0.24217118997912318, 0.17954070981210857, 0.16701461377870563, 0.17536534446764093, 0.19832985386221294, 0.24843423799582465, 0.19624217118997914, 0.2045929018789144, 0.2630480167014614, 0.2630480167014614, 0.27139874739039666, 0.18162839248434237, 0.1544885177453027, 0.05636743215031315, 0.029227557411273485, 0.0020876826722338203, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0020876826722338203, 0.08768267223382047, 0.19624217118997914, 0.19206680584551147, 0.2359081419624217, 0.22755741127348644, 0.21920668058455114, 0.267223382045929, 0.2651356993736952, 0.2651356993736952, 0.2588726513569937, 0.2546972860125261, 0.22338204592901878, 0.18580375782881003, 0.2546972860125261, 0.2839248434237996, 0.24217118997912318, 0.17118997912317327, 0.17954070981210857, 0.07515657620041753, 0.033402922755741124, 0.008350730688935281, 0.0020876826722338203, 0.0020876826722338203, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.06680584551148225, 0.15031315240083507, 0.23382045929018788, 0.2150313152400835, 0.21294363256784968, 0.17536534446764093, 0.1837160751565762, 0.21920668058455114, 0.21711899791231734, 0.19624217118997914, 0.18162839248434237, 0.19624217118997914, 0.25260960334029225, 0.2651356993736952, 0.2359081419624217, 0.20250521920668058, 0.15657620041753653, 0.07306889352818371, 0.04384133611691023, 0.012526096033402923, 0.0041753653444676405, 0.0020876826722338203, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.03549060542797495, 0.11691022964509394, 0.18789144050104384, 0.23799582463465555, 0.23382045929018788, 0.20041753653444677, 0.17118997912317327, 0.15657620041753653, 0.15866388308977036, 0.17745302713987474, 0.19624217118997914, 0.2630480167014614, 0.25260960334029225, 0.2651356993736952, 0.19624217118997914, 0.12108559498956159, 0.0918580375782881, 0.05010438413361169, 0.012526096033402923, 0.0020876826722338203, 0.0, 0.0020876826722338203, 0.0020876826722338203, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0041753653444676405, 0.054279749478079335, 0.12108559498956159, 0.20041753653444677, 0.2609603340292276, 0.31106471816283926, 0.32150313152400833, 0.29436325678496866, 0.26931106471816285, 0.3173277661795407, 0.32150313152400833, 0.31106471816283926, 0.2546972860125261, 0.16075156576200417, 0.09812108559498957, 0.06680584551148225, 0.022964509394572025, 0.010438413361169102, 0.0041753653444676405, 0.0020876826722338203, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0041753653444676405, 0.0020876826722338203, 0.012526096033402923, 0.020876826722338204, 0.054279749478079335, 0.08977035490605428, 0.08977035490605428, 0.10438413361169102, 0.10020876826722339, 0.09394572025052192, 0.10438413361169102, 0.1022964509394572, 0.06263048016701461, 0.04592901878914405, 0.025052192066805846, 0.010438413361169102, 0.0041753653444676405, 0.0041753653444676405, 0.0020876826722338203, 0.0, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0020876826722338203, 0.0041753653444676405, 0.0041753653444676405, 0.0020876826722338203, 0.0020876826722338203, 0.0020876826722338203, 0.0041753653444676405, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],
    #  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]]
